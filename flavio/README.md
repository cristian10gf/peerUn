# PeerEval DÃºo â€” Propuesta de SoluciÃ³n

> **Estudiante:** Flavio Arregoces    
> **Proyecto:** AplicaciÃ³n mÃ³vil de evaluaciÃ³n entre pares para trabajo colaborativo universitario  
> **Fecha:** 22 de febrero de 2026  
> **TecnologÃ­as definidas:** 

![Flutter](https://img.shields.io/badge/Flutter-02569B?style=for-the-badge&logo=flutter&logoColor=white)
![GetX](https://img.shields.io/badge/GetX-8A2BE2?style=for-the-badge)
![Clean Architecture](https://img.shields.io/badge/Clean_Architecture-4CAF50?style=for-the-badge)
![Roble](https://img.shields.io/badge/Roble-Auth-FF6B35?style=for-the-badge)
![Brightspace](https://img.shields.io/badge/Brightspace-Integration-0072C6?style=for-the-badge)


---

## Tabla de Contenidos

1. [Referentes Analizados](#1-referentes-analizados)
2. [ComposiciÃ³n y DiseÃ±o de la SoluciÃ³n](#2-composiciÃ³n-y-diseÃ±o-de-la-soluciÃ³n)
3. [Flujo Funcional Detallado](#3-flujo-funcional-detallado)
4. [JustificaciÃ³n de la Propuesta](#4-justificaciÃ³n-de-la-propuesta)

---

## 1. Referentes Analizados

### 1.1 WebPA (Loughborough University)

**DescripciÃ³n general**

WebPA es un sistema open source de evaluaciÃ³n entre pares desarrollado en la Universidad de Loughborough, Reino Unido. Su caracterÃ­stica mÃ¡s notable es el algoritmo WebPA, que toma la nota grupal y la redistribuye individualmente segÃºn las evaluaciones recibidas de los compaÃ±eros. Ha sido adoptado por universidades del Reino Unido y Australia y su cÃ³digo fuente estÃ¡ disponible pÃºblicamente.

**GestiÃ³n de grupos**

Los grupos se crean en WebPA manualmente o importando un archivo CSV. No tiene integraciÃ³n con ningÃºn LMS. El administrador del sistema crea cursos y el instructor gestiona grupos dentro de cada curso. No hay sincronizaciÃ³n automÃ¡tica con plataformas externas.

**Proceso de evaluaciÃ³n**

1. El instructor crea una evaluaciÃ³n y define los grupos participantes y la ventana de tiempo.
2. Los estudiantes acceden mediante usuario y contraseÃ±a y evalÃºan a sus compaÃ±eros de grupo.
3. El sistema calcula el factor WebPA para cada estudiante y lo aplica sobre la nota grupal para obtener la nota individual.

**Criterios de evaluaciÃ³n**

El instructor define los criterios libremente (entre 1 y 10 criterios). Cada uno se puntÃºa en una escala de 0 a 100. No impone descriptores conductuales; los define el instructor o se dejan en blanco.

**VisualizaciÃ³n de resultados**

- *Instructor:* factores WebPA por estudiante, puntajes por criterio, exportaciÃ³n CSV.
- *Estudiante:* puede ver su factor WebPA y el promedio recibido por criterio si el instructor lo permite.

**Limitaciones relevantes**

- Sin app mÃ³vil nativa.
- Sin integraciÃ³n con Brightspace ni ningÃºn LMS.
- El algoritmo WebPA asume que la nota del grupo ya estÃ¡ definida; no funciona como evaluaciÃ³n independiente.
- Interfaz visualmente anticuada.
- Sin notificaciones activas; el estudiante solo se entera si entra a la plataforma.
- Sin soporte en espaÃ±ol.

---

### 1.2 FeedbackFruits

**DescripciÃ³n general**

FeedbackFruits es una plataforma EdTech neerlandesa (Ãmsterdam) que ofrece un conjunto de herramientas de aprendizaje activo, incluyendo evaluaciÃ³n entre pares, retroalimentaciÃ³n sobre vÃ­deos y autoevaluaciÃ³n. Se integra con los principales LMS mediante LTI 1.3. Su enfoque es facilitar al mÃ¡ximo la adopciÃ³n por parte del instructor, con una configuraciÃ³n guiada paso a paso y plantillas predefinidas.

**GestiÃ³n de grupos**

FeedbackFruits se integra directamente con los grupos existentes en el LMS vÃ­a LTI. Si el instructor tiene grupos en Canvas, Brightspace o Moodle, FeedbackFruits los importa automÃ¡ticamente sin pasos adicionales. Cualquier cambio de composiciÃ³n grupal en el LMS se refleja automÃ¡ticamente.

**Proceso de evaluaciÃ³n**

1. El instructor configura la actividad directamente desde el LMS (como si fuera una tarea mÃ¡s del curso).
2. Los estudiantes evalÃºan a sus compaÃ±eros segÃºn los criterios definidos.
3. FeedbackFruits envÃ­a recordatorios automÃ¡ticos por correo antes del cierre.
4. El instructor puede liberar los resultados cuando lo decida.

**Criterios de evaluaciÃ³n**

FeedbackFruits ofrece plantillas predefinidas de criterios para trabajo colaborativo (similares a los del enunciado: puntualidad, contribuciÃ³n, comunicaciÃ³n, etc.) y permite al instructor modificarlas. La escala es configurable: numÃ©rica (1-5, 1-10) o cualitativa.

**VisualizaciÃ³n de resultados**

- *Instructor:* dashboard con tasas de participaciÃ³n, promedios por criterio, comparativo entre grupos.
- *Estudiante:* retroalimentaciÃ³n recibida con comentarios de los evaluadores (con control de anonimato).

**Limitaciones relevantes**

- Es de pago; requiere licencia institucional con Brightspace.
- Sin app mÃ³vil nativa; funciona embebido en el LMS a travÃ©s del navegador.
- La experiencia del usuario depende de la calidad de la integraciÃ³n LTI de la instituciÃ³n.
- Sin soporte completo en espaÃ±ol.

---

### 1.3 Peerceptiv

**DescripciÃ³n general**

Peerceptiv es una plataforma de evaluaciÃ³n entre pares desarrollada en la Universidad Carnegie Mellon (CMU). Originalmente se llamaba Peergrader y fue creada como proyecto de investigaciÃ³n acadÃ©mica. En 2017 se convirtiÃ³ en una empresa independiente (Peerceptiv Inc., Pittsburgh, PA). EstÃ¡ diseÃ±ada principalmente para evaluaciÃ³n de trabajos escritos, pero incluye mÃ³dulos de evaluaciÃ³n de desempeÃ±o colaborativo.

**GestiÃ³n de grupos**

Los grupos se gestionan dentro de Peerceptiv. Permite importar listas de estudiantes desde CSV y tiene integraciÃ³n LTI con Canvas. No tiene integraciÃ³n oficial con Brightspace.

**Proceso de evaluaciÃ³n**

Peerceptiv tiene un enfoque de *calibraciÃ³n*: antes de evaluar a compaÃ±eros, los estudiantes practican evaluando ejemplos de referencia. Esto mejora la consistencia y reduce el sesgo. El instructor define cuÃ¡ntas evaluaciones debe hacer cada estudiante.

**Criterios de evaluaciÃ³n**

Los criterios los define el instructor. Peerceptiv permite criterios cuantitativos (escala numÃ©rica) y cualitativos (rubric con descriptores). TambiÃ©n permite la evaluaciÃ³n anÃ³nima o identificada segÃºn decisiÃ³n del instructor.

**VisualizaciÃ³n de resultados**

- *Instructor:* reportes de participaciÃ³n, distribuciÃ³n de puntajes, detecciÃ³n de evaluadores inconsistentes.
- *Estudiante:* retroalimentaciÃ³n recibida, puntaje promedio y comparativo con la media del grupo.

**Limitaciones relevantes**

- Sin app mÃ³vil nativa.
- Sin integraciÃ³n con Brightspace.
- El modelo de calibraciÃ³n es valioso pero aÃ±ade pasos al flujo que pueden resultar complejos en el contexto del proyecto.
- Es de pago.
- Sin soporte en espaÃ±ol.

---

### Tabla comparativa de referentes

| CaracterÃ­stica | WebPA | FeedbackFruits | Peerceptiv |
|---|:---:|:---:|:---:|
| App mÃ³vil nativa | âŒ | âŒ | âŒ |
| IntegraciÃ³n con Brightspace | âŒ | âœ… LTI | âŒ |
| Sin autoevaluaciÃ³n por defecto | âœ… | âœ… | âœ… |
| Criterios configurables | âœ… Libre | âœ… Plantillas | âœ… Libre |
| Visibilidad pÃºblica/privada | âœ… | âœ… | âœ… |
| Ventana de tiempo configurable | âœ… | âœ… | âœ… |
| Notificaciones push | âŒ | âŒ Email | âŒ Email |
| Roles diferenciados (UI distinta) | âœ… | âœ… | âœ… |
| Open source | âœ… | âŒ | âŒ |
| Disponible en espaÃ±ol | âŒ | âš ï¸ Parcial | âŒ |
| Costo | ğŸ†“ Gratuito | ğŸ’° Pago | ğŸ’° Pago |

> **Oportunidad identificada:** FeedbackFruits es el Ãºnico que se integra con Brightspace, pero requiere licencia institucional y no tiene app mÃ³vil. Los tres muestran que la separaciÃ³n de experiencias por rol (instructor vs. estudiante) mejora la usabilidad. PeerEval DÃºo lleva esa separaciÃ³n al extremo: dos apps completamente independientes, con identidades visuales distintas y cÃ³digo de presentaciÃ³n sin cruce de lÃ³gica entre roles.

---

## 2. ComposiciÃ³n y DiseÃ±o de la SoluciÃ³n

### 2.1 DecisiÃ³n de arquitectura: dos apps Flutter independientes con lÃ³gica de dominio compartida

**Se proponen dos aplicaciones Flutter separadas:** `peereval_teacher` para docentes y `peereval_student` para estudiantes, organizadas en un monorepo con un package Dart compartido (`peereval_core`) que contiene la capa de dominio y de datos. Cada app implementa Ãºnicamente su capa de presentaciÃ³n.

**Alternativas descartadas:**

| Alternativa | RazÃ³n de descarte |
|---|---|
| Una sola app con roles | La UX Ã³ptima para cada rol implica decisiones de diseÃ±o que se contradicen: el docente necesita densidad de informaciÃ³n, el estudiante necesita simplicidad extrema. Mezclarlos en una sola app obliga a compromisos que perjudican a los dos. |
| Dos apps sin cÃ³digo compartido | Duplica la lÃ³gica de negocio: entidades, repositorios y casos de uso tendrÃ­an que mantenerse en dos lugares distintos. Cualquier correcciÃ³n de bug requerirÃ­a hacerla dos veces. |
| App + plataforma web | La gestiÃ³n en web estÃ¡ justificada solo si hay datos de un volumen que no puede mostrarse cÃ³modamente en mÃ³vil. Para el alcance del proyecto, la app del docente es suficiente. |

**JustificaciÃ³n:**
- WebPA y FeedbackFruits tienen interfaces deliberadamente distintas para instructor y estudiante dentro del mismo sistema. PeerEval DÃºo lleva esa separaciÃ³n al nivel de producto, lo que permite diseÃ±ar cada app pensando exclusivamente en su usuario.
- Con dos apps separadas, la app del estudiante no contiene fÃ­sicamente el cÃ³digo de las funciones de administraciÃ³n. No hay lÃ³gica condicional que proteger; el cÃ³digo simplemente no estÃ¡.
- El package `peereval_core` evita duplicaciÃ³n: entidades, casos de uso y repositorios se escriben una sola vez y los dos proyectos los consumen.

---

### 2.2 Arquitectura tÃ©cnica

```
peereval_duo/  (monorepo)
â”œâ”€â”€ packages/
â”‚   â””â”€â”€ peereval_core/          â† package Dart compartido
â”‚       â”œâ”€â”€ domain/
â”‚       â”‚   â”œâ”€â”€ entities/       â† Usuario, Curso, Grupo, Evaluacion...
â”‚       â”‚   â”œâ”€â”€ usecases/       â† casos de uso por rol
â”‚       â”‚   â””â”€â”€ repositories/   â† interfaces (contratos)
â”‚       â””â”€â”€ data/
â”‚           â”œâ”€â”€ models/         â† JSON serializable
â”‚           â”œâ”€â”€ datasources/    â† Roble API, Brightspace API, cachÃ© local
â”‚           â””â”€â”€ repositories/   â† implementaciones
â”‚
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ peereval_teacher/       â† Flutter app (docentes)
â”‚   â”‚   â””â”€â”€ presentation/
â”‚   â”‚       â”œâ”€â”€ dashboard/
â”‚   â”‚       â”œâ”€â”€ courses/
â”‚   â”‚       â”œâ”€â”€ groups/
â”‚   â”‚       â”œâ”€â”€ assessments/
â”‚   â”‚       â””â”€â”€ results/
â”‚   â”‚
â”‚   â””â”€â”€ peereval_student/       â† Flutter app (estudiantes)
â”‚       â””â”€â”€ presentation/
â”‚           â”œâ”€â”€ courses/
â”‚           â”œâ”€â”€ evaluation/
â”‚           â””â”€â”€ results/
â”‚
â””â”€â”€ melos.yaml                  â† gestiÃ³n del monorepo con Melos
```

| Capa | Responsabilidad | UbicaciÃ³n |
|---|---|---|
| PresentaciÃ³n | Widgets, controllers GetX, rutas | Cada app por separado |
| Dominio | Entidades, casos de uso, interfaces | `peereval_core` |
| Datos | Modelos JSON, repositorios, datasources | `peereval_core` |

---



## 3. Flujo Funcional Detallado

### 3.1 Flujo del docente (peereval_teacher)

```
ONBOARDING
    â”‚
    â–¼
[Login con Roble â€” app de docente]
    â”‚  Credenciales â†’ JWT con rol = "teacher"
    â”‚  Si el JWT devuelve rol = "student": error â†’ descargar peereval_student
    â–¼
[Crear curso]
    â”‚  Nombre â†’ guardado en Roble DB
    â”‚  Se genera cÃ³digo de invitaciÃ³n automÃ¡ticamente
    â–¼
[Importar grupos desde Brightspace]
    â”‚  Pantalla "Importar grupos" â†’ trae categorÃ­as del curso vÃ­a API
    â”‚  Tabla de vista previa: nombre, cÃ³digo Brightspace, miembros
    â”‚  El docente selecciona las categorÃ­as a importar y confirma
    â”‚  Si hay cambios posteriores â†’ re-importar; si hay eval. activa â†’ diferir
    â–¼
[Crear evaluaciÃ³n]
    â”‚  1. Nombre de la actividad
    â”‚  2. CategorÃ­a de grupo objetivo
    â”‚  3. DuraciÃ³n (horas)
    â”‚  4. Visibilidad: PÃºblica o Privada
    â”‚  Confirmar â†’ push a todos los estudiantes de los grupos seleccionados
    â–¼
[Monitorear]
    â”‚  Barra de completitud en tiempo real: X/N completadas
    â–¼
[Ver resultados]
    â”œâ”€â”€ Promedio por actividad (todos los grupos)
    â”œâ”€â”€ Promedio por grupo (entre actividades)
    â”œâ”€â”€ Promedio por estudiante (entre actividades)
    â””â”€â”€ Detalle: grupo â†’ estudiante â†’ puntaje por criterio
```

---

### 3.2 Flujo del estudiante (peereval_student)

```
ONBOARDING
    â”‚
    â–¼
[Login con Roble â€” app de estudiante]
    â”‚  JWT con rol = "student"
    â”‚  Si el JWT devuelve rol = "teacher": error â†’ descargar peereval_teacher
    â”‚  Ingresar cÃ³digo de invitaciÃ³n del docente â†’ unirse al curso
    â–¼
[Ver mis cursos y mi grupo]
    â”‚  Lista de cursos con nombre del grupo y compaÃ±eros
    â–¼
[NotificaciÃ³n push]
    â”‚  "Nueva evaluaciÃ³n activa: [nombre] â€” Tienes [X] horas"
    â–¼
[Realizar evaluaciÃ³n]
    â”‚
    â”‚  Para cada compaÃ±ero (sin autoevaluaciÃ³n):
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  â”‚  CRITERIO: CONTRIBUCIONES                               â”‚
    â”‚  â”‚  â—‹ 2.0 â€“ Necesita Mejorar                              â”‚
    â”‚  â”‚      "Estuvo en todo momento como observador..."       â”‚
    â”‚  â”‚  â—‹ 3.0 â€“ Adecuado                                      â”‚
    â”‚  â”‚      "En algunas ocasiones participÃ³..."               â”‚
    â”‚  â”‚  â—‹ 4.0 â€“ Bueno                                         â”‚
    â”‚  â”‚      "Hizo varios aportes; puede ser mÃ¡s propositivo"  â”‚
    â”‚  â”‚  â— 5.0 â€“ Excelente                                     â”‚
    â”‚  â”‚      "Sus aportes enriquecieron el trabajo del equipo" â”‚
    â”‚  â”‚                                                         â”‚
    â”‚  â”‚  [PUNTUALIDAD]  [COMPROMISO]  [ACTITUD]                â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚  Progreso: compaÃ±ero X de N â†’ confirmar al finalizar todos
    â–¼
[Ver resultados â€” solo si evaluaciÃ³n es PÃºblica]
    â”‚  Promedio recibido por criterio
    â””â”€â”€ Promedio general
```

---

### 3.3 Mapa de navegaciÃ³n

```
peereval_teacher
â”œâ”€â”€ /login
â”œâ”€â”€ /dashboard              â†’ resumen de cursos y evaluaciones activas
â”œâ”€â”€ /courses/:id
â”‚   â”œâ”€â”€ /groups             â†’ importar y sincronizar desde Brightspace
â”‚   â”œâ”€â”€ /assessments
â”‚   â”‚   â”œâ”€â”€ /new            â†’ crear evaluaciÃ³n
â”‚   â”‚   â””â”€â”€ /:assId/results â†’ resultados por nivel de detalle
â”‚   â””â”€â”€ /invite             â†’ cÃ³digo de invitaciÃ³n del curso
â””â”€â”€ /profile

peereval_student
â”œâ”€â”€ /login                  â†’ cÃ³digo de invitaciÃ³n al registrarse
â”œâ”€â”€ /home                   â†’ mis cursos y evaluaciones activas
â”œâ”€â”€ /courses/:id
â”‚   â”œâ”€â”€ /my-group           â†’ mis compaÃ±eros
â”‚   â””â”€â”€ /assessments
â”‚       â””â”€â”€ /:assId/evaluate â†’ formulario peer-to-peer
â””â”€â”€ /profile
```

---

## 4. JustificaciÃ³n de la Propuesta

### 4.1 Basada en referentes

**WebPA** demuestra que la separaciÃ³n de interfaces por rol mejora la usabilidad: el instructor ve datos densos y el estudiante solo ve su formulario. TambiÃ©n introduce la idea de redistribuciÃ³n de nota segÃºn evaluaciÃ³n grupal, que muestra que las instituciones confÃ­an en este tipo de herramientas para decisiones de calificaciÃ³n reales. La debilidad de WebPA es que no tiene app mÃ³vil y que su algoritmo depende de que ya exista una nota grupal; PeerEval DÃºo resuelve esto operando como herramienta independiente de calificaciÃ³n.

**FeedbackFruits** es el referente mÃ¡s cercano en tÃ©rminos de integraciÃ³n con el LMS: importa grupos directamente desde Brightspace vÃ­a LTI, que es exactamente lo que necesita el proyecto. Su limitaciÃ³n es que no tiene app mÃ³vil y que requiere licencia institucional. PeerEval DÃºo replica el concepto de importaciÃ³n desde Brightspace (via API en lugar de LTI) y lo lleva al contexto de app nativa.

**Peerceptiv** valida el concepto de que la detecciÃ³n de evaluadores inconsistentes es un valor agregado real. Aunque PeerEval DÃºo no implementa calibraciÃ³n ni detecciÃ³n de outliers en esta versiÃ³n, la arquitectura de dos apps separadas facilita aÃ±adir esa funcionalidad en el futuro a la app del docente sin afectar la app del estudiante.

**Brecha cubierta:** ninguno de los tres tiene app mÃ³vil nativa. En el contexto universitario colombiano, donde el acceso principal es desde celular, una app Flutter nativa garantiza notificaciones push oportunas y una UX fluida que una web responsiva no puede igualar.

---

### 4.2 Tabla resumen de decisiones

| DecisiÃ³n | JustificaciÃ³n |
|---|---|
| Dos apps separadas con dominio compartido | UX especializada por rol; seguridad por diseÃ±o (el estudiante no tiene acceso fÃ­sico al cÃ³digo del docente) |
| Monorepo con package `peereval_core` | Evita duplicaciÃ³n de lÃ³gica de negocio; FeedbackFruits y Peerceptiv confirman que la lÃ³gica puede centralizarse |
| Grupos importados desde Brightspace | Alineado con FeedbackFruits; elimina reingreso manual de datos ya existentes en el LMS |
| VerificaciÃ³n de rol al login en cada app | Si un docente usa la app de estudiante (o viceversa), recibe un error claro con indicaciÃ³n de la app correcta |
| Criterios fijos BARS Ã— 4 sin configuraciÃ³n | Reduce carga de setup al docente y garantiza comparabilidad |
| Notificaciones push vÃ­a FCM | Los tres referentes solo usan correo; esto no es suficiente para ventanas de evaluaciÃ³n cortas |
| Sin autoevaluaciÃ³n | Enunciado explÃ­cito; simplifica el formulario del estudiante |
| Visibilidad pÃºblica/privada por evaluaciÃ³n | Necesidad confirmada en los tres referentes |

---
## 5. Capturas de UI â€” PeerEval
### 5.1 UI Profesor
| Pantalla | Captura |
|---|:---:|
| **Login** â€” (Roble) | ![Login](captures\Login.png) | 
| **Dashboard**  | ![Registro](captures\Dashboard.png) |
| **Grupos**  | ![Grupos](captures\Grupos.png) |
| **EvaluaciÃ³n**  | ![EvaluaciÃ³n](captures\EvaluaciÃ³n.png) | 
| **Resultados**  | ![Resultados](captures\Resultados.png) |
| **Resultados - Detalle**  | ![Resultados-Detalle](captures\Resultados-Detalle.png) |

### 5.2 UI Estudiante
| Pantalla | Captura |
|---|:---:|
| **Login** â€” (Roble) | ![Login](captures\Login_estudiante.png) | 
| **Cursos**  | ![Cursos](captures\Cursos.png) |
| **Evaluar**  | ![Evaluar](captures\Evaluar.png) |
| **Criterios**  | ![Criterios](captures\Criterios.png) | 
| **Resultados**  | ![Resultados](captures\Resultados_estudiante.png) |


*Propuesta elaborada por Flavio Arregoces â€” Febrero 2026*